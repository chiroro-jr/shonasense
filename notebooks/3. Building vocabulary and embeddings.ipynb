{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a432d05-1f03-4619-ae52-2ad674f1f545",
   "metadata": {},
   "source": [
    "# Building a vocabulary and word embeddings\n",
    "The requirement is to build 2 models: 1 that uses it's own embeddings and another that uses word embeddings built with Gensim. The first one will use `Tokenizer` to generate encoded sequences from the input text and also built a vocabulary. The second model will use Gensim's learned vocabulary and some helper functions for encoding and decoding the encoded sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55bb9f2f-f862-4583-b3fd-b8a50f0706b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASETS_DIR = \"../datasets\"\n",
    "MODELS_DIR = \"../models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bcbc5-bc91-46ab-9792-9216008c579f",
   "metadata": {},
   "source": [
    "## Load the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40549069-6e29-48af-b88f-dcae8c2321c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['premier soccer league psl iri kudya magaka mambishi zvichitevera mhirizhonga yakaitika',\n",
       " 'soccer league psl iri kudya magaka mambishi zvichitevera mhirizhonga yakaitika kubabourfields',\n",
       " 'league psl iri kudya magaka mambishi zvichitevera mhirizhonga yakaitika kubabourfields kubulawayo',\n",
       " 'psl iri kudya magaka mambishi zvichitevera mhirizhonga yakaitika kubabourfields kubulawayo nezuro']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only\n",
    "  file = open(filename, 'r')\n",
    "\n",
    "  # read all the text\n",
    "  text = file.read()\n",
    "\n",
    "  # close the file\n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "in_filename = f\"{DATASETS_DIR}/content_sequences.txt\"\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "lines[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be1469-ffa5-4db5-9ca7-fa2650a7b5ac",
   "metadata": {},
   "source": [
    "## Encoding sequences using `Tokenizer`\n",
    "The word embedding layer expects sequences to be comprised of integers. Each word in the doc can be mapped into a unique integer and encode the text sequences. Later, when making predictions, the prediction numbers can be converted and look up their associated words in the same mapping. The `Tokenizer` from Keras will be used for this. It first needs to be trained on the entire training dataset so that it finds all the unique words in the data and assigns each a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55087aef-393d-486d-b81b-85aa7705b0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# integer encode the sequences of words\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c642a1-f973-49f2-a8b4-3bd40f5f1e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2766"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fd1f48-d01b-43a1-a04f-f34d8f1ff777",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Word -> Index\n",
      "-------------\n",
      "kuti -> 1\n",
      "iyi -> 2\n",
      "uye -> 3\n",
      "vanoti -> 4\n",
      "vanodaro -> 5\n"
     ]
    }
   ],
   "source": [
    "# print a couple of word:index pairs from the learned word index\n",
    "count = 0\n",
    "print(\"-------------\")\n",
    "print(\"Word -> Index\")\n",
    "print(\"-------------\")\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    print(f\"{word} -> {index}\")\n",
    "    count += 1\n",
    "    \n",
    "    if count > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4e4e47-a79d-47f4-96c3-79466ffa3cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer for later usage (checkpoint)\n",
    "from pickle import dump\n",
    "\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open(f'{MODELS_DIR}/tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89cf60-540f-446f-b050-d53e1a595ae2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoding sequences using `Word2Vec`\n",
    "I want to achieve the same goal as `Tokenizer` but instead using the vocabulary and word index learned by Gensim's `Word2Vec` since those will be different from the ones `Tokenizer` comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ea60a5-1917-4c57-b9b4-adc487fd13de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the word embeddings\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [line.split() for line in lines]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5d2c9c-6bda-4464-aed8-9c2c67a547f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2765"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(w2v_model.wv.key_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f337aa-5557-4b54-8f2b-9297c9718f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Word -> Index\n",
      "-------------\n",
      "kuti -> 0\n",
      "iyi -> 1\n",
      "uye -> 2\n",
      "vanoti -> 3\n",
      "vanodaro -> 4\n"
     ]
    }
   ],
   "source": [
    "# print a couple of word:index pairs from the learned word index\n",
    "count = 0\n",
    "print(\"-------------\")\n",
    "print(\"Word -> Index\")\n",
    "print(\"-------------\")\n",
    "for word, index in w2v_model.wv.key_to_index.items():\n",
    "    print(f\"{word} -> {index}\")\n",
    "    count += 1\n",
    "    \n",
    "    if count > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aedcbdfb-8fe9-4f44-971b-1b110db71582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the word embedding model\n",
    "w2v_model.save(f\"{MODELS_DIR}/word2vec.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
